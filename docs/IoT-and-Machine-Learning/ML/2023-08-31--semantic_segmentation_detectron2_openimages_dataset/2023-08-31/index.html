<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-IoT-and-Machine-Learning/ML/2023-08-31--semantic_segmentation_detectron2_openimages_dataset/index" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.1">
<title data-rh="true">Detectron Object Detection with OpenImages Dataset (WIP) | Mike Polinowski</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2023-08-31--semantic_segmentation_detectron2_openimages_dataset/2023-08-31"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Detectron Object Detection with OpenImages Dataset (WIP) | Mike Polinowski"><meta data-rh="true" name="description" content="Detectron2 is a platform for object detection, segmentation and other visual recognition tasks."><meta data-rh="true" property="og:description" content="Detectron2 is a platform for object detection, segmentation and other visual recognition tasks."><link data-rh="true" rel="icon" href="/img/icons/favicon-32x32.png"><link data-rh="true" rel="canonical" href="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2023-08-31--semantic_segmentation_detectron2_openimages_dataset/2023-08-31"><link data-rh="true" rel="alternate" href="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2023-08-31--semantic_segmentation_detectron2_openimages_dataset/2023-08-31" hreflang="en"><link data-rh="true" rel="alternate" href="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2023-08-31--semantic_segmentation_detectron2_openimages_dataset/2023-08-31" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Mike Polinowski RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Mike Polinowski Atom Feed">




<link rel="icon" href="/img/angular_momentum.png">
<link rel="manifest" href="/manifest.json">
<meta name="theme-color" content="rgb(37,194,160)">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#000">
<link rel="apple-touch-icon" href="/img/angular_momentum.png">
<link rel="mask-icon" href="/img/angular_momentum.png" color="rgb(33,33,33)">
<meta name="msapplication-TileImage" content="/img/angular_momentum.png">
<meta name="msapplication-TileColor" content="#000">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-P74BDWF0C6"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-P74BDWF0C6",{})</script><link rel="stylesheet" href="/assets/css/styles.08c8c484.css">
<script src="/assets/js/runtime~main.afcb95e1.js" defer="defer"></script>
<script src="/assets/js/main.fb0a52c3.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/angular_momentum.png" alt="Mike Polinowski :: Dev Notebook" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/angular_momentum.png" alt="Mike Polinowski :: Dev Notebook" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Mike Polinowski</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/docs/tags">Tags</a><a class="navbar__item navbar__link" href="/Search">Search</a><a href="https://mpolinowski.github.io/Personal" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">About<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/mpolinowski" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/development">Development</a><button aria-label="Expand sidebar category &#x27;Development&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/devops">DevOps</a><button aria-label="Expand sidebar category &#x27;DevOps&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/docs/category/machine-learning-ai-and-computer-vision">Machine Learning, AI and Computer Vision</a><button aria-label="Collapse sidebar category &#x27;Machine Learning, AI and Computer Vision&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/docs/category/machine-learning">Machine Learning</a><button aria-label="Collapse sidebar category &#x27;Machine Learning&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-10-01--delib-face-detection/2023-10-01">DLIB Face Recognition</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-23--yolo8-listen/2023-09-23">Audio Classification with Computer Vision</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-21--cvat-automatic-annotation/2023-09-21">CVAT Semi-automatic and Automatic Annotation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-19--cvat-computer-vision-annotation-tool/2023-09-19">Computer Vision Annotation Tool (CVAT) Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-17--yolo8-nightshift/2023-09-17">YOLOv8 Nightshift</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-15--yolo8-tracking-and-ocr/2023-09-15">YOLOv8 License Plate Detection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-10--model-explainability-shap/2023-09-11">Scikit-Learn ML Model Explainability</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-05--semantic-segmentation-in-opencv/2023-09-05">Using Tensorflow Models in OpenCV</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-01--yolo-i-know-flowers/2023-09-01">YOLOv8 Image Classifier</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-31--semantic_segmentation_detectron2_openimages_dataset/2023-08-31">Detectron Object Detection with OpenImages Dataset (WIP)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-30--instance_segmentation_detectron2_model_zoo_mask_rcnn/2023-08-30">Instance Segmentation with PyTorch (Mask RCNN)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-29--semantic-segmentation-detectron2-model-zoo-faster-rcnn/2023-08-29">Image Segmentation with PyTorch (Faster RCNN)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-28--semantic-segmentation-detectron2-model-zoo/2023-08-28">Image Segmentation with PyTorch (RCNN)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-27--image-segmentation-with-pytorch/2023-08-27">Image Segmentation with PyTorch</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-21--pytorch-development-in-docker/2023-08-21">Containerized PyTorch Dev Workflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-13-tensorflow-i-know-flowers-model-eval/2023-08-13">Tensorflow Image Classifier - Model Evaluation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-12-tensorflow-i-know-flowers-xception/2023-08-12">Tensorflow Image Classifier - Xception</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-11-tensorflow-i-know-flowers-vit/2023-08-11">Tensorflow Image Classifier - ViT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-10-tensorflow-i-know-flowers-nasnetmobile/2023-08-10">Tensorflow Image Classifier - NASNetMobile</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-09-tensorflow-i-know-flowers-mobilenetv3small/2023-08-09">Tensorflow Image Classifier - MobileNetV3Small</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-08-tensorflow-i-know-flowers-mobilenetv3large/2023-08-08">Tensorflow Image Classifier - MobileNetV3Large</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-07-tensorflow-i-know-flowers-mobilenetv2/2023-08-07">Tensorflow Image Classifier - MobileNetV2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-06-tensorflow-i-know-flowers-inceptionv3/2023-08-06">Tensorflow Image Classifier - InceptionV3</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-05-tensorflow-i-know-flowers-efficientnetv2s/2023-08-05">Tensorflow Image Classifier - EfficientNetV2S</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-04-tensorflow-i-know-flowers-efficientnetv2b0/2023-08-04">Tensorflow Image Classifier - EfficientNetV2B0</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-03-tensorflow-i-know-flowers-deit/2023-08-03">Tensorflow Image Classifier - Data-efficient Image Transformers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-02-tensorflow-i-know-flowers-preprocessing/2023-08-02">Tensorflow Image Classifier - Data Pre-processing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-01-tensorflow-i-know-flowers-intro/2023-08-01">Tensorflow Image Classifier - Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-27-tensorflow-vision-transformer/2023-07-27">Tensorflow VITs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-26-tensorflow-human-emotion-detector/2023-07-26">Human Emotion Detection with Tensorflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-25-onnx-models/2023-07-25">Working with ONNX Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-21-introduction-to-pytorch-caffe2/2023-07-21">Introduction to Caffe2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-02-sql-in-data-science-ml/2023-07-02">SQL in Data Science - Machine Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-06-30-sql-in-data-science-advanced/2023-06-30">SQL in Data Science - Slightly more Advanced Queries</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-06-27-sql-in-data-science-basics/2023-06-27">SQL in Data Science - The Basics using Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-06-26-autogluon-transit-photometry-dataset/2023-06-26">Detection of Exoplanets using Transit Photometry</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-19-tensorflow-natural-language-processing/2023-04-19">(Re) Introduction to Tensorflow Natural Language Processing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-16-deep-3d-image-segmentation/2023-04-16">3D Image Classification</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-14-manifold-learning-for-image-segmentation/2023-04-14">Dimensionality Reduction for Image Segmentation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-13-fisher-discriminant-analysis/2023-04-13">Fisher Linear Discriminant Analysis (LDA)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-13-isometric-mapping/2023-04-13">Isometric Mapping (ISOMAP)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-13-multi-dimensional-scaling/2023-04-13">Multidimensional Scaling (MDS)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-12-tstochastic-neighbor-embedding/2023-04-12">tStochastic Neighbor Embedding (t-SNE)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-11-locally-linear-embedding/2023-04-11">Locally Linear Embedding (LLE)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-09-principal-component-analysis/2023-04-09">Principal Component Analysis (PCA)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-26-tensorflow-unsupervised-learning-generative-adversial-networks/2023-03-26">Tensorflow 2 - Unsupervised Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-26-tensorflow-unsupervised-learning-autoencoders-super-resolution/2023-03-26">Tensorflow 2 - Unsupervised Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/2023-03-24">Tensorflow 2 - Unsupervised Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-16-tensorflow-transfer-learning-scaling/2023-03-16">Tensorflow 2 - Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-11-tensorflow-transfer-learning-fine-tuning/2023-03-11">Tensorflow 2 - Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-06-tensorflow-transfer-learning-feature-extraction/2023-03-06">Tensorflow 2 - Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-05-tensorflow-convolutional-neural-network-multiclass-classifications/2023-03-05">Tensorflow 2 - Convolutional Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-03-tensorflow-convolutional-neural-network-binary-classifications/2023-03-03">Tensorflow 2 - Convolutional Neural Networks</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-02-tensorflow-neural-network-multi-classification/2023-03-02">Tensorflow 2 - Neural Network Classifications</a><button aria-label="Expand sidebar category &#x27;Tensorflow 2 - Neural Network Classifications&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-28-tensorflow-neural-network-classification-model-evaluation/2023-02-28">Tensorflow 2 - Neural Network Classification</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-27-tensorflow-neural-network-classification/2023-02-27">Tensorflow 2 - Neural Network Classification</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-data-preprocessing/2023-02-26">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-real-dataset/2023-02-26">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-25-tensorflow-neural-network-regression-experiments/2023-02-25">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-24-tensorflow-neural-network-regression-evaluation/2023-02-24">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-23-tensorflow-neural-network-regression/2023-02-23">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-22-tensorflow-tensors-3/2023-02-22">Tensorflow 2 - An (Re)Introduction 2023 (3)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-21-tensorflow-tensors-2/2023-02-21">Tensorflow 2 - An (Re)Introduction 2023 (2)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-19-tensorflow-introduction/2023-02-19">Tensorflow 2 - An (Re)Introduction 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-18-keras-introduction-vgg16/2023-02-18">Keras for Tensorflow - VGG16 Network Architecture</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-18-keras-introduction-rnn/2023-02-18">Keras for Tensorflow - Recurrent Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-17-keras-introduction-cnn/2023-02-17">Keras for Tensorflow - Convolutional Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-16-keras-introduction-ann/2023-02-16">Keras for Tensorflow - Artificial Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-15-as-one-yolo-object-tracking/2023-02-15">YOLOv8 with AS-One</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-14-keras-introduction/2023-02-14">Keras for Tensorflow - An (Re)Introduction 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-30-predicting-wine-quality/2023-01-30">SciKit Wine Quality</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-28-opencv-coin-counter/2023-01-28">OpenCV Count My Money</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-14-yolov7_to_tensorflow/2023-01-14">YOLOv7 to Tensorflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-13-yolov7_data_conversion/2023-01-13">YOLOv7 Label Conversion</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-10-yolov7_custom_data/2023-01-10">YOLOv7 Training with Custom Data</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-08-depth-vision-midas/2023-01-08">MiDaS Depth Vision</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-05-yolov7/2023-01-05">YOLOv7 Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-31-tf-rnn-text-generation/2022-12-31">Recurrent Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-28-tf-gan-image-generator/2022-12-28">Deep Convolutional Generative Adversarial Network</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-21-tf-downsampling/2022-12-21">Tensorflow Downsampling</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-21-tf-deepdream/2022-12-21">Tensorflow Deep Dream</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-20-tf-representation/2022-12-19">Tensorflow Representation Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-19-tf-hub/2022-12-19">Tensorflow Hub</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-18-tf-transfer-learning/2022-12-18">Tensorflow Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-16-tf-cifar/2022-12-16">Tensorflow Image Classification</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-12-tf-breast-cancer-classification-part6/2022-12-12">Breast Histopathology Image Segmentation Part 6</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-12-tf-breast-cancer-classification-part5/2022-12-12">Breast Histopathology Image Segmentation Part 5</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-11-tf-breast-cancer-classification-part4/2022-12-11">Breast Histopathology Image Segmentation Part 4</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-11-tf-breast-cancer-classification-part3/2022-12-11">Breast Histopathology Image Segmentation Part 3</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-11-tf-breast-cancer-classification-part2/2022-12-11">Breast Histopathology Image Segmentation Part 2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-10-tf-breast-cancer-classification-part1/2022-12-10">Breast Histopathology Image Segmentation Part 1</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-11-27-containerized-deep-learning/2022-11-27">Deep Docker on Arch</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-04-pytorch-face-restoration/2022-04-04">Face Restoration with GFPGAN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-03-pytorch-real-super-resolution/2022-04-03">Super Resolution with Real-ESRGAN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-02-pytorch-super-resolution/2022-04-02">Super Resolution with ESRGAN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-01-tensorflow-audio-classifier/2022-04-01">Deep Audio</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/2022-02-20">Yolo App - YOLOv5 Data Preparation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-19--yolo-app-flask/2022-02-19">Yolo App - Flask Web Application</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-18--yolo-app-ocr/2022-02-18">Yolo App - Tesseract Optical Character Recognition</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-17--yolo-app-prediction-pipeline/2022-02-17">Yolo App - Pipeline Predictions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-16--yolo-app-tensorflow-model/2022-02-16">Yolo App - Train a Model with Tensorflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-15--yolo-app-get-data/2022-02-15">Yolo App - Data Collection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-10--opencv-optical-flow-tracking/2021-12-10">OpenCV Optical Flow Algorithm for Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-09--opencv-camshift-tracking/2021-12-09">OpenCV CAMshift Algorithm for Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-08--opencv-meanshift-tracking/2021-12-08">OpenCV Meanshift Algorithm for Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-07--opencv-detection-and-tracking/2021-12-07">OpenCV Object Detection and Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-06--opencv-object-tracking/2021-12-06">OpenCV Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-05--opencv-face-detection/2021-12-05">OpenCV Face Detection and Privacy</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-04--opencv-image-objects/2021-12-04">OpenCV Image Objects</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-03--opencv-image-operations/2021-12-03">OpenCV Image Operations</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-02--opencv-with-videos/2021-12-02">OpenCV, Streams and Video Files</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-01--opencv-with-images/2021-12-01">OpenCV and Images</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-15--facebook-prophet-introduction/2021-11-15">Introduction into FB Prophet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-14--tensorflow-model-for-tfjs/2021-11-14">Tensorflow.js React App</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-13--tensorflow-model-zoo/2021-11-13">Tensorflow2 Model Zoo</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-12--tensorflow-crash-course-part-v/2021-11-12">Tensorflow2 Crash Course - Part V</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-11--tensorflow-crash-course-part-iv/2021-11-11">Tensorflow2 Crash Course - Part IV</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-10--tensorflow-crash-course-part-iii/2021-11-10">Tensorflow2 Crash Course - Part III</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-09--tensorflow-crash-course-part-ii/2021-11-09">Tensorflow2 Crash Course - Part II</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-08--tensorflow-crash-course-part-i/2021-11-08">Tensorflow Crash Course - Part I</a><button aria-label="Expand sidebar category &#x27;Tensorflow Crash Course - Part I&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-07--opencv-crash-course-part-ii/2021-11-07">OpenCV Crash Course Part II</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-06--opencv-crash-course-part-i/2021-11-06">OpenCV Crash Course Part I</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-05--license-plates-yolov4-opencv-tesseract/2021-11-05">License Plate Recognition with YOLOv4, OpenCV and Tesseract</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-04--installing-yolov4/2021-11-04">Installing YOLOv4 with Anaconda</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-03--streamlit-opencv-mediapipe/2021-11-03">Streamlit user interface for openCV/Mediapipe face mesh app</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-02--spacy_ner_predictions/2021-11-02">spaCy NER Predictions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-01--spacy_natural_language_processing/2021-11-01">spaCy NER on Arch Linux</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2019-04-01--introduction-to-keras/2019-04-01">Introduction to Keras</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-10-31--tesseract_ocr_arch_linux/2021-10-31">Tesseract OCR on Arch Linux</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2019-03-31--introduction-to-tensorflow-2-beta/2019-03-31">Introduction to TensorFlow 2 Beta</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2018-01-02--machine-learning-with-python/2018-01-02">Machine Learning with SciKit Learn</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/category/aiops">AIOps</a><button aria-label="Expand sidebar category &#x27;AIOps&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/automation-deep-vision-and-robotics">Automation, Deep Vision and Robotics</a><button aria-label="Expand sidebar category &#x27;Automation, Deep Vision and Robotics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/machine-learning-ai-and-computer-vision"><span itemprop="name">Machine Learning, AI and Computer Vision</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/machine-learning"><span itemprop="name">Machine Learning</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Detectron Object Detection with OpenImages Dataset (WIP)</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><p><img alt="TST, Hong Kong" src="/assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-f940fa4541ff8a00764cf3f41cd6b985.jpg" width="1500" height="811"></p>
<ul>
<li><a href="#detectron-object-detection-with-openimages-dataset-wip">Detectron Object Detection with OpenImages Dataset (WIP)</a>
<ul>
<li><a href="#dataset">Dataset</a>
<ul>
<li><a href="#curate-dataset-by-class">Curate Dataset by Class</a></li>
</ul>
</li>
<li><a href="#model-training">Model Training</a></li>
<li><a href="#model-evaluation">Model Evaluation</a></li>
<li><a href="#model-predictions">Model Predictions</a></li>
</ul>
</li>
</ul>
<ul>
<li><a href="https://github.com/mpolinowski/pt-seg-i-see-you">Github Repository</a></li>
</ul>
<p><strong>Related</strong>:</p>
<ul>
<li><a href="/docs/IoT-and-Machine-Learning/ML/2023-08-27--image-segmentation-with-pytorch/2023-08-27">Image Segmentation with PyTorch</a></li>
<li><a href="/docs/IoT-and-Machine-Learning/ML/2023-08-28--semantic-segmentation-detectron2-model-zoo/2023-08-28">Semantic Segmentation Detectron2 Model Zoo</a></li>
<li><a href="/docs/IoT-and-Machine-Learning/ML/2023-08-29--semantic-segmentation-detectron2-model-zoo-faster-rcnn/2023-08-29">Semantic Segmentation Detectron2 Model Zoo: Faster RCNN</a></li>
<li><a href="/docs/IoT-and-Machine-Learning/ML/2023-08-30--instance_segmentation_detectron2_model_zoo_mask_rcnn/2023-08-30">Semantic Segmentation Detectron2 Model Zoo: Mask RCNN</a></li>
<li>Detectron Object Detection with OpenImages Dataset (WIP)</li>
</ul>
<h1 id="detectron-object-detection-with-openimages-dataset-wip">Detectron Object Detection with OpenImages Dataset (WIP)</h1>
<h2 id="dataset">Dataset</h2>
<p>Download the annotations for the detection boxes from <a href="https://storage.googleapis.com/openimages/web/download_v7.html">OpenImages</a>:</p>
<pre><code class="language-python">!pip install opencv-python
</code></pre>
<pre><code class="language-python">!python -m pip install &#x27;git+https://github.com/facebookresearch/detectron2.git&#x27;
</code></pre>
<pre><code class="language-python">import ast
import json
import cv2 as cv
import matplotlib.pyplot as plt
import numpy as np
import os
import random
import shutil
import torch

from detectron2 import model_zoo
from detectron2.config import get_cfg as _get_cfg
from detectron2.data import MetadataCatalog, DatasetCatalog, build_detection_train_loader
from detectron2.engine import DefaultTrainer, HookBase, DefaultPredictor
from detectron2.structures import BoxMode
import detectron2.utils.comm as comm
</code></pre>
<pre><code class="language-python">!wget https://storage.googleapis.com/openimages/v6/oidv6-train-annotations-bbox.csv -P &#x27;../datasets/OpenImages/annotations&#x27;
!wget https://storage.googleapis.com/openimages/v5/validation-annotations-bbox.csv -P &#x27;../datasets/OpenImages/annotations&#x27;
!wget https://storage.googleapis.com/openimages/v5/test-annotations-bbox.csv -P &#x27;../datasets/OpenImages/annotations&#x27;

!wget https://raw.githubusercontent.com/openimages/dataset/master/downloader.py -P &#x27;./helper&#x27;
</code></pre>
<p>--2023-09-02 15:26:06--  <a href="https://storage.googleapis.com/openimages/v5/test-annotations-bbox.csv">https://storage.googleapis.com/openimages/v5/test-annotations-bbox.csv</a>
Loaded CA certificate &#x27;/etc/ssl/certs/ca-certificates.crt&#x27;
Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.214.144, 172.217.164.112, 142.250.72.208, ...
Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.214.144|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 77484237 (74M) [text/csv]
Saving to: ../datasets/OpenImages/annotations/test-annotations-bbox.csv</p>
<p>test-annotations-bb 100%[===================&gt;]  73.89M  8.05MB/s    in 12s</p>
<p>2023-09-02 15:26:19 (6.31 MB/s) - ../datasets/OpenImages/annotations/test-annotations-bbox.csv saved [77484237/77484237]</p>
<h3 id="curate-dataset-by-class">Curate Dataset by Class</h3>
<ul>
<li>Scripts by <a href="https://github.com/computervisioneng/train-yolov8-custom-dataset-step-by-step-guide/tree/master/prepare_data">computervisioneng</a></li>
<li>Get class IDs from <a href="https://gist.github.com/mpolinowski/7b297ad73545e0c670a248a2c350b011">here</a></li>
</ul>
<pre><code class="language-python"># Create a text file containing all the image IDs that you&#x27;re interested in downloading.

class_id = &#x27;/m/01g317&#x27; # &#x27;Person&#x27;
# class_id = &#x27;/m/0k4j&#x27; # &#x27;Car&#x27;
# class_id = &#x27;/m/0h2r6&#x27; # &#x27;Van&#x27;
# class_id = &#x27;/m/01bjv&#x27; # &#x27;Bus&#x27;
# class_id = &#x27;/m/07r04&#x27; # &#x27;Truck&#x27;
# class_id = &#x27;/m/01jfm_&#x27; # &#x27;Vehicle registration plate&#x27;
# class_id = &#x27;/m/01lrl&#x27; # &#x27;Carnivore&#x27;

train_bboxes_filename = &#x27;../datasets/OpenImages/annotations/oidv6-train-annotations-bbox.csv&#x27;
validation_bboxes_filename = &#x27;../datasets/OpenImages/annotations/validation-annotations-bbox.csv&#x27;
test_bboxes_filename = &#x27;../datasets/OpenImages/annotations/test-annotations-bbox.csv&#x27;

image_list_file_path = &#x27;../datasets/OpenImages/image_class_person.txt&#x27;
# image_list_file_path = &#x27;../datasets/OpenImages/image_class_car.txt&#x27;
# image_list_file_path = &#x27;../datasets/OpenImages/image_class_van.txt&#x27;
# image_list_file_path = &#x27;../datasets/OpenImages/image_class_bus.txt&#x27;
# image_list_file_path = &#x27;../datasets/OpenImages/image_class_truck.txt&#x27;
# image_list_file_path = &#x27;../datasets/OpenImages/image_class_plates.txt&#x27;
# image_list_file_path = &#x27;../datasets/OpenImages/image_class_carnivore.txt&#x27;
</code></pre>
<pre><code class="language-python">image_list_file_list = []
for j, filename in enumerate([train_bboxes_filename, validation_bboxes_filename, test_bboxes_filename]):
    print(filename)
    with open(filename, &#x27;r&#x27;) as f:
        line = f.readline()
        while len(line) != 0:
            id, _, class_name, _, x1, x2, y1, y2, _, _, _, _, _ = line.split(&#x27;,&#x27;)[:13]
            if class_name in [class_id] and id not in image_list_file_list:
                image_list_file_list.append(id)
                with open(image_list_file_path, &#x27;a&#x27;) as fw:
                    fw.write(&#x27;{}/{}\n&#x27;.format([&#x27;train&#x27;, &#x27;validation&#x27;, &#x27;test&#x27;][j], id))
            line = f.readline()

        f.close()

# the download returned 395931 images with class &#x27;Person&#x27; -&gt; I reduced them to 1% over all classes (3961) for this test run
</code></pre>
<pre><code class="language-python"># Run the following script to download all files, making sure you have the dependencies installed:

# !python helper/downloader.py --image_list=&#x27;../datasets/OpenImages/image_class_person.txt&#x27; --download_folder=&#x27;../datasets/OpenImages/complete&#x27; --num_processes=5
!python helper/downloader.py &#x27;../datasets/OpenImages/image_class_person_1%.txt&#x27; --download_folder=&#x27;../datasets/OpenImages/complete&#x27; --num_processes=5
</code></pre>
<p>Downloading images: 100%|| 3961/3961 [17:32,  3.76it/s]</p>
<pre><code class="language-python"># get ids for all files from list that were used
file_ids = []

text_file = &#x27;../datasets/OpenImages/image_class_person_1%.txt&#x27;
files_list = open(text_file, &#x27;r&#x27;)

lines = files_list.readlines()

for line in lines:
    file_ids.append(line.strip()[-16:])
</code></pre>
<pre><code class="language-python">print(len(file_ids))
</code></pre>
<p>3961</p>
<pre><code class="language-python">for j, filename in enumerate([train_bboxes_filename, validation_bboxes_filename, test_bboxes_filename]):
    print(j, filename)
</code></pre>
<p>0 ../datasets/OpenImages/annotations/oidv6-train-annotations-bbox.csv
1 ../datasets/OpenImages/annotations/validation-annotations-bbox.csv
2 ../datasets/OpenImages/annotations/test-annotations-bbox.csv</p>
<pre><code class="language-python"># Train/Test/Split + generate YOLO compatible annotations
DATA_ALL_DIR = &#x27;../datasets/OpenImages/complete&#x27;
DATA_OUT_DIR = &#x27;../datasets/OpenImages/split&#x27;

# create directories
for set_ in [&#x27;train&#x27;, &#x27;validation&#x27;, &#x27;test&#x27;]:
    for dir_ in [os.path.join(DATA_OUT_DIR, set_),
                 os.path.join(DATA_OUT_DIR, set_, &#x27;imgs&#x27;),
                 os.path.join(DATA_OUT_DIR, set_, &#x27;anns&#x27;)]:
        if os.path.exists(dir_):
            shutil.rmtree(dir_)
        os.mkdir(dir_)

# save images and annotations
for j, filename in enumerate([train_bboxes_filename, validation_bboxes_filename, test_bboxes_filename]):
    set_ = [&#x27;train&#x27;, &#x27;validation&#x27;, &#x27;test&#x27;][j]
    print(filename)
    with open(filename, &#x27;r&#x27;) as f:
        line = f.readline()
        while len(line) != 0:
            # get bbox
            id, _, class_name, _, x1, x2, y1, y2, _, _, _, _, _ = line.split(&#x27;,&#x27;)[:13]
            # take all bboxes with the correct class
            if class_name in [class_id]:
                # but remove all that are not used (the example only uses 1% of all available images)
                if id in file_ids:
                    if not os.path.exists(os.path.join(DATA_OUT_DIR, set_, &#x27;imgs&#x27;, &#x27;{}.jpg&#x27;.format(id))):
                        shutil.copy(os.path.join(DATA_ALL_DIR, &#x27;{}.jpg&#x27;.format(id)),
                                    os.path.join(DATA_OUT_DIR, set_, &#x27;imgs&#x27;, &#x27;{}.jpg&#x27;.format(id)))
                    # yolo conform annotations
                    with open(os.path.join(DATA_OUT_DIR, set_, &#x27;anns&#x27;, &#x27;{}.txt&#x27;.format(id)), &#x27;a&#x27;) as f_ann:
                        # class_id, xc, yx, w, h
                        x1, x2, y1, y2 = [float(j) for j in [x1, x2, y1, y2]]
                        xc = (x1 + x2) / 2
                        yc = (y1 + y2) / 2
                        w = x2 - x1
                        h = y2 - y1
    
                        f_ann.write(&#x27;0 {} {} {} {}\n&#x27;.format(xc, yc, w, h))
                        f_ann.close()

            line = f.readline()
</code></pre>
<p>../datasets/OpenImages/annotations/oidv6-train-annotations-bbox.csv
../datasets/OpenImages/annotations/validation-annotations-bbox.csv
../datasets/OpenImages/annotations/test-annotations-bbox.csv</p>
<pre><code class="language-python">IMGS_TRAIN_DIR = DATA_OUT_DIR + &#x27;/train/imgs&#x27;
ANNS_TRAIN_DIR = DATA_OUT_DIR + &#x27;/train/anns&#x27;

if __name__ == &quot;__main__&quot;:
    files = os.listdir(IMGS_TRAIN_DIR)
    while True:
        fig = plt.figure()
        k = random.randint(0, len(files) - 1)
        img = cv.imread(os.path.join(IMGS_TRAIN_DIR, files[k]))
        ann_file = os.path.join(ANNS_TRAIN_DIR, files[k][:-4] + &#x27;.txt&#x27;)

        h_img, w_img, _ = img.shape
        with open(ann_file, &#x27;r&#x27;) as f:
            lines = [l[:-1] for l in f.readlines() if len(l) &gt; 2]
            for line in lines:
                line = line.split(&#x27; &#x27;)
                class_, x0, y0, w, h = line
                x1 = int((float(x0) - (float(w) / 2)) * w_img)
                y1 = int((float(y0) - (float(h) / 2)) * h_img)
                x2 = x1 + int(float(w) * w_img)
                y2 = y1 + int(float(h) * h_img)
                img = cv.rectangle(img,
                                    (x1, y1),
                                    (x2, y2),
                                    (0, 255, 0),
                                    4)
        mng = plt.get_current_fig_manager()
        plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))
        plt.show()
</code></pre>
<p><img alt="Model Training" src="/assets/images/Model_Eval_01-33892eb88f17b07e8eac443d4cfb8b1e.webp" width="1260" height="935"></p>
<h2 id="model-training">Model Training</h2>
<pre><code class="language-python"># create loss function https://github.com/computervisioneng/train-object-detector-detectron2
class ValidationLoss(HookBase):
    &quot;&quot;&quot;
    A hook that computes validation loss during training.

    Attributes:
        cfg (CfgNode): The detectron2 config node.
        _loader (iterator): An iterator over the validation dataset.
    &quot;&quot;&quot;

    def __init__(self, cfg):
        &quot;&quot;&quot;
        Args:
            cfg (CfgNode): The detectron2 config node.
        &quot;&quot;&quot;
        super().__init__()
        self.cfg = cfg.clone()
        # Switch to the validation dataset
        self.cfg.DATASETS.TRAIN = cfg.DATASETS.VAL
        # Build the validation data loader iterator
        self._loader = iter(build_detection_train_loader(self.cfg))

    def after_step(self):
        &quot;&quot;&quot;
        Computes the validation loss after each training step.
        &quot;&quot;&quot;
        # Get the next batch of data from the validation data loader
        data = next(self._loader)
        with torch.no_grad():
            # Compute the validation loss on the current batch of data
            loss_dict = self.trainer.model(data)

            # Check for invalid losses
            losses = sum(loss_dict.values())
            assert torch.isfinite(losses).all(), loss_dict

            # Reduce the loss across all workers
            loss_dict_reduced = {&quot;val_&quot; + k: v.item() for k, v in
                                 comm.reduce_dict(loss_dict).items()}
            losses_reduced = sum(loss for loss in loss_dict_reduced.values())

            # Save the validation loss in the trainer storage
            if comm.is_main_process():
                self.trainer.storage.put_scalars(total_val_loss=losses_reduced,
                                                 **loss_dict_reduced)
</code></pre>
<pre><code class="language-python"># create detectron2 configuration https://github.com/computervisioneng/train-object-detector-detectron2
def get_cfg(output_dir, learning_rate, batch_size, iterations, checkpoint_period, model, device, nmr_classes):
    &quot;&quot;&quot;
    Create a Detectron2 configuration object and set its attributes.

    Args:
        output_dir (str): The path to the output directory where the trained model and logs will be saved.
        learning_rate (float): The learning rate for the optimizer.
        batch_size (int): The batch size used during training.
        iterations (int): The maximum number of training iterations.
        checkpoint_period (int): The number of iterations between consecutive checkpoints.
        model (str): The name of the model to use, which should be one of the models available in Detectron2&#x27;s model zoo.
        device (str): The device to use for training, which should be &#x27;cpu&#x27; or &#x27;cuda&#x27;.
        nmr_classes (int): The number of classes in the dataset.

    Returns:
        The Detectron2 configuration object.
    &quot;&quot;&quot;
    cfg = _get_cfg()

    # Merge the model&#x27;s default configuration file with the default Detectron2 configuration file.
    cfg.merge_from_file(model_zoo.get_config_file(model))
    # Set the training and validation datasets and exclude the test dataset.
    cfg.DATASETS.TRAIN = (&#x27;train&#x27;)
    cfg.DATASETS.VAL = (&#x27;validation&#x27;)
    cfg.DATASETS.TEST = ()
    # Set the device to use for training.
    if device in [&#x27;cpu&#x27;]:
        cfg.MODEL.DEVICE = &#x27;cpu&#x27;
    # Set the number of data loader workers.
    cfg.DATALOADER.NUM_WORKERS = 2
    # Set the model weights to the ones pre-trained on the COCO dataset.
    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)
    # Set the batch size used by the solver.
    cfg.SOLVER.IMS_PER_BATCH = batch_size
    # Set the checkpoint period.
    cfg.SOLVER.CHECKPOINT_PERIOD = checkpoint_period
    # Set the base learning rate.
    cfg.SOLVER.BASE_LR = learning_rate
    # Set the maximum number of training iterations.
    cfg.SOLVER.MAX_ITER = iterations
    # Set the learning rate scheduler steps to an empty list, which means the learning rate will not be decayed.
    cfg.SOLVER.STEPS = []
    # Set the batch size used by the ROI heads during training.
    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128
    # Set the number of classes.
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = nmr_classes
    # Set the output directory.
    cfg.OUTPUT_DIR = output_dir
    
    return cfg
</code></pre>
<pre><code class="language-python"># get dataset https://github.com/computervisioneng/train-object-detector-detectron2
def get_dicts(img_dir, ann_dir):
    &quot;&quot;&quot;
    Read the annotations for the dataset in YOLO format and create a list of dictionaries containing information for each
    image.

    Args:
        img_dir (str): Directory containing the images.
        ann_dir (str): Directory containing the annotations.

    Returns:
        list[dict]: A list of dictionaries containing information for each image. Each dictionary has the following keys:
            - file_name: The path to the image file.
            - image_id: The unique identifier for the image.
            - height: The height of the image in pixels.
            - width: The width of the image in pixels.
            - annotations: A list of dictionaries, one for each object in the image, containing the following keys:
                - bbox: A list of four integers [x0, y0, w, h] representing the bounding box of the object in the image,
                        where (x0, y0) is the top-left corner and (w, h) are the width and height of the bounding box,
                        respectively.
                - bbox_mode: A constant from the `BoxMode` class indicating the format of the bounding box coordinates
                             (e.g., `BoxMode.XYWH_ABS` for absolute coordinates in the format [x0, y0, w, h]).
                - category_id: The integer ID of the object&#x27;s class.
    &quot;&quot;&quot;
    dataset_dicts = []
    for idx, file in enumerate(os.listdir(ann_dir)):
        # annotations should be provided in yolo format

        record = {}

        filename = os.path.join(img_dir, file[:-4] + &#x27;.jpg&#x27;)
        height, width = cv.imread(filename).shape[:2]

        record[&quot;file_name&quot;] = filename
        record[&quot;image_id&quot;] = idx
        record[&quot;height&quot;] = height
        record[&quot;width&quot;] = width

        objs = []
        with open(os.path.join(ann_dir, file)) as r:
            lines = [l[:-1] for l in r.readlines()]

        for _, line in enumerate(lines):
            if len(line) &gt; 2:
                label, cx, cy, w_, h_ = line.split(&#x27; &#x27;)

                obj = {
                    &quot;bbox&quot;: [int((float(cx) - (float(w_) / 2)) * width),
                             int((float(cy) - (float(h_) / 2)) * height),
                             int(float(w_) * width),
                             int(float(h_) * height)],
                    &quot;bbox_mode&quot;: BoxMode.XYWH_ABS,
                    &quot;category_id&quot;: int(label),
                }

                objs.append(obj)
        record[&quot;annotations&quot;] = objs
        dataset_dicts.append(record)
    return dataset_dicts
</code></pre>
<pre><code class="language-python"># register dataset https://github.com/computervisioneng/train-object-detector-detectron2
def register_datasets(root_dir, class_list_file):
    &quot;&quot;&quot;
    Registers the train and validation datasets and returns the number of classes.

    Args:
        root_dir (str): Path to the root directory of the dataset.
        class_list_file (str): Path to the file containing the list of class names.

    Returns:
        int: The number of classes in the dataset.
    &quot;&quot;&quot;
    # Read the list of class names from the class list file.
    with open(class_list_file, &#x27;r&#x27;) as reader:
        classes_ = [l[:-1] for l in reader.readlines()]

    # Register the train and validation datasets.
    for d in [&#x27;train&#x27;, &#x27;validation&#x27;]:
        DatasetCatalog.register(d, lambda d=d: get_dicts(os.path.join(root_dir, d, &#x27;imgs&#x27;),
                                                         os.path.join(root_dir, d, &#x27;anns&#x27;)))
        # Set the metadata for the dataset.
        MetadataCatalog.get(d).set(thing_classes=classes_)

    return len(classes_)
</code></pre>
<pre><code class="language-python"># train the dataset
def train(output_dir, data_dir, class_list_file, learning_rate, batch_size, iterations, checkpoint_period, device,
          model):
    &quot;&quot;&quot;
    Train a Detectron2 model on a custom dataset.

    Args:
        output_dir (str): Path to the directory to save the trained model and output files.
        data_dir (str): Path to the directory containing the dataset.
        class_list_file (str): Path to the file containing the list of class names in the dataset.
        learning_rate (float): Learning rate for the optimizer.
        batch_size (int): Batch size for training.
        iterations (int): Maximum number of training iterations.
        checkpoint_period (int): Number of iterations after which to save a checkpoint of the model.
        device (str): Device to use for training (e.g., &#x27;cpu&#x27; or &#x27;cuda&#x27;).
        model (str): Name of the model configuration to use. Must be a key in the Detectron2 model zoo.

    Returns:
        None
    &quot;&quot;&quot;

    # Register the dataset and get the number of classes
    nmr_classes = register_datasets(data_dir, class_list_file)

    # Get the configuration for the model
    cfg = get_cfg(output_dir, learning_rate, batch_size, iterations, checkpoint_period, model, device, nmr_classes)

    # Create the output directory
    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)

    # Create the trainer object
    trainer = DefaultTrainer(cfg)

    # Create a custom validation loss object
    val_loss = ValidationLoss(cfg)

    # Register the custom validation loss object as a hook to the trainer
    trainer.register_hooks([val_loss])

    # Swap the positions of the evaluation and checkpointing hooks so that the validation loss is logged correctly
    trainer._hooks = trainer._hooks[:-2] + trainer._hooks[-2:][::-1]

    # Resume training from a checkpoint or load the initial model weights
    trainer.resume_or_load(resume=False)

    # Train the model
    trainer.train()
</code></pre>
<pre><code class="language-python">CLASSES = &#x27;../datasets/OpenImages/class_names.txt&#x27; # add classes to this file - 1 per line
DATA_DIR = &#x27;../datasets/OpenImages/split&#x27; # point to dir that contains your train/validation/test folders
OUTPUT_DIR = &#x27;../saved_models/OpenImages_Model&#x27; # weight will be saved here at interval set below
DEVICE = &#x27;gpu&#x27; # &#x27;cpu&#x27;
LR = 0.00001
BATCH_SIZE = 4
ITERATIONS = 12000 # how many epochs do you want to train?
CHECKPOINT_PERIOD = 3000 # save weights at this epoch interval
# MODEL= &#x27;COCO-Detection/fast_rcnn_R_50_FPN_1x.yaml&#x27; # 2.6 GB Train Mem
MODEL= &#x27;COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml&#x27; # 3.0 GB Train Mem
# MODEL= &#x27;COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml&#x27; # 4.1 GB Train Mem
# MODEL = &#x27;COCO-Detection/retinanet_R_101_FPN_3x.yaml&#x27; # 5.2 GB Train Mem
</code></pre>
<pre><code class="language-python">train(
    OUTPUT_DIR,
    DATA_DIR,
    CLASSES,
    device=DEVICE,
    learning_rate=float(LR),
    batch_size=int(BATCH_SIZE),
    iterations=int(ITERATIONS),
    checkpoint_period=int(CHECKPOINT_PERIOD),
    model=MODEL)
</code></pre>
<blockquote>
<p><strong>Problem</strong>: <code>Skip loading parameter &#x27;roi_heads.box_predictor.cls_score.weight&#x27; to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.</code></p>
</blockquote>
<p>WIP</p>
<pre><code class="language-bash">    [32m[09/03 16:20:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3671 images left.
    [32m[09/03 16:20:53 d2.data.build]: [0mDistribution of instances among all 1 categories:
    [36m|  category  | #instances   |
    |:----------:|:-------------|
    |   Person   | 15218        |
    |            |              |[0m
    [32m[09/03 16:20:53 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style=&#x27;choice&#x27;), RandomFlip()]
    [32m[09/03 16:20:53 d2.data.build]: [0mUsing training sampler TrainingSampler
    [32m[09/03 16:20:53 d2.data.common]: [0mSerializing the dataset using: &lt;class &#x27;detectron2.data.common._TorchSerializedList&#x27;&gt;
    [32m[09/03 16:20:53 d2.data.common]: [0mSerializing 3671 elements to byte tensors and concatenating them all ...
    [32m[09/03 16:20:53 d2.data.common]: [0mSerialized dataset takes 1.17 MiB
    [32m[09/03 16:20:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 72 images left.
    [32m[09/03 16:20:54 d2.data.build]: [0mDistribution of instances among all 1 categories:
    [36m|  category  | #instances   |
    |:----------:|:-------------|
    |   Person   | 197          |
    |            |              |[0m
    [32m[09/03 16:20:54 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style=&#x27;choice&#x27;), RandomFlip()]
    [32m[09/03 16:20:54 d2.data.build]: [0mUsing training sampler TrainingSampler
    [32m[09/03 16:20:54 d2.data.common]: [0mSerializing the dataset using: &lt;class &#x27;detectron2.data.common._TorchSerializedList&#x27;&gt;
    [32m[09/03 16:20:54 d2.data.common]: [0mSerializing 72 elements to byte tensors and concatenating them all ...
    [32m[09/03 16:20:54 d2.data.common]: [0mSerialized dataset takes 0.02 MiB
    [32m[09/03 16:20:54 d2.checkpoint.detection_checkpoint]: [0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...


    model_final_280758.pkl: 167MB [00:21, 7.86MB/s]                                                                                                        
    Skip loading parameter &#x27;roi_heads.box_predictor.cls_score.weight&#x27; to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.
    Skip loading parameter &#x27;roi_heads.box_predictor.cls_score.bias&#x27; to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.
    Skip loading parameter &#x27;roi_heads.box_predictor.bbox_pred.weight&#x27; to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.
    Skip loading parameter &#x27;roi_heads.box_predictor.bbox_pred.bias&#x27; to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.
    Some model parameters or buffers are not found in the checkpoint:
    [34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
    [34mroi_heads.box_predictor.cls_score.{bias, weight}[0m


    [32m[09/03 16:21:15 d2.engine.train_loop]: [0mStarting training from iteration 0
    
...

    [32m[09/03 22:11:31 d2.utils.events]: [0m eta: 0:00:00  iter: 11999  total_loss: 0.6341  loss_cls: 0.1783  loss_box_reg: 0.3643  loss_rpn_cls: 0.01865  loss_rpn_loc: 0.02812  total_val_loss: 0.7417  val_loss_cls: 0.2803  val_loss_box_reg: 0.4251  val_loss_rpn_cls: 0.02334  val_loss_rpn_loc: 0.02181    time: 1.2499  last_time: 1.3406  data_time: 0.0571  last_data_time: 0.0050   lr: 1e-05  max_mem: 4713M
    [32m[09/03 22:11:37 d2.engine.hooks]: [0mOverall training speed: 11998 iterations in 4:09:55 (1.2499 s / it)
    [32m[09/03 22:11:37 d2.engine.hooks]: [0mTotal training time: 5:50:16 (1:40:20 on hooks)
</code></pre>
<h2 id="model-evaluation">Model Evaluation</h2>
<p>Visualizing the <code>metrics.json</code> file generated in your above defined output dir:</p>
<pre><code class="language-python">def moving_average(a, n=3):
    ret = np.cumsum(a, dtype=float)
    ret[n:] = ret[n:] - ret[:-n]
    return ret[n - 1:] / n


metrics_file = OUTPUT_DIR + &#x27;/metrics.json&#x27;

with open(metrics_file, &#x27;r&#x27;) as f:
    metrics = [ast.literal_eval(l[:-1]) for l in f.readlines()]
    f.close()

train_loss = [float(v[&#x27;loss_box_reg&#x27;]) for v in metrics if &#x27;loss_box_reg&#x27; in v.keys()]
val_loss = [float(v[&#x27;val_loss_box_reg&#x27;]) for v in metrics if &#x27;val_loss_box_reg&#x27; in v.keys()]

N = 40

train_loss_avg = moving_average(train_loss, n=N)
val_loss_avg = moving_average(val_loss, n=N)
</code></pre>
<pre><code class="language-python">plt.plot(range(20 * N - 1, 20 * len(train_loss), 20), train_loss_avg, label=&#x27;train loss&#x27;)
plt.plot(range(20 * N - 1, 20 * len(train_loss), 20), val_loss_avg, label=&#x27;val loss&#x27;)
plt.title(&#x27;Faster RCNN R50-FPN-3x Training Loss&#x27;)
plt.legend()
plt.grid()
plt.show()
</code></pre>
<p><img alt="Model Training" src="/assets/images/Model_Eval_02-9284f234ccf3b7a7326b5f307f4a14d3.webp" width="556" height="435"></p>
<h2 id="model-predictions">Model Predictions</h2>
<pre><code class="language-python"># Load config from a config file
cfg = _get_cfg()
cfg.merge_from_file(model_zoo.get_config_file(MODEL))
cfg.MODEL.WEIGHTS = OUTPUT_DIR + &#x27;/model_0011999.pth&#x27;
cfg.MODEL.DEVICE = &#x27;cuda&#x27;
</code></pre>
<pre><code class="language-python"># Create predictor instance
predictor = DefaultPredictor(cfg)

# Load image
image = cv.imread(OUTPUT_DIR + &quot;/sz.jpg&quot;)

# Perform prediction
outputs = predictor(image)
</code></pre>
<pre><code class="language-python">outputs
</code></pre>
<pre><code class="language-python"># Display predictions
threshold = 0.5

preds = outputs[&quot;instances&quot;].pred_classes.tolist()
scores = outputs[&quot;instances&quot;].scores.tolist()
bboxes = outputs[&quot;instances&quot;].pred_boxes
</code></pre>
<pre><code class="language-python">for j, bbox in enumerate(bboxes):
    bbox = bbox.tolist()

    score = scores[j]
    pred = preds[j]

    if score &gt; threshold:
        x1, y1, x2, y2 = [int(i) for i in bbox]

        cv.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 5)

cv.imshow(&#x27;image&#x27;, image)
cv.waitKey(0)
</code></pre></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/python">Python</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/machine-learning">Machine Learning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/py-torch">PyTorch</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2023-08-31--semantic_segmentation_detectron2_openimages_dataset/index.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/IoT-and-Machine-Learning/ML/2023-09-01--yolo-i-know-flowers/2023-09-01"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">YOLOv8 Image Classifier</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/IoT-and-Machine-Learning/ML/2023-08-30--instance_segmentation_detectron2_model_zoo_mask_rcnn/2023-08-30"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Instance Segmentation with PyTorch (Mask RCNN)</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#dataset" class="table-of-contents__link toc-highlight">Dataset</a><ul><li><a href="#curate-dataset-by-class" class="table-of-contents__link toc-highlight">Curate Dataset by Class</a></li></ul></li><li><a href="#model-training" class="table-of-contents__link toc-highlight">Model Training</a></li><li><a href="#model-evaluation" class="table-of-contents__link toc-highlight">Model Evaluation</a></li><li><a href="#model-predictions" class="table-of-contents__link toc-highlight">Model Predictions</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Research</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Notebook</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/tags">Tags</a></li><li class="footer__item"><a class="footer__link-item" href="/Curriculum-Vitae">CV</a></li></ul></div><div class="col footer__col"><div class="footer__title">Social</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/in/mike-polinowski-6396ba121/" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/MikePolinowski" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.flickr.com/people/149680084@N06/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Flickr<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/mpolinowski" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright  2024 Mike Polinowski, INSTAR Deutschland GmbH, Shenzhen - China.</div></div></div></footer></div>
</body>
</html>